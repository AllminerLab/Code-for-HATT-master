{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11942cf1-04c8-417f-9364-7d31ea493ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, scipy.sparse as sp\n",
    "import torch.optim as optim, torch.nn.functional as F\n",
    "import torch_sparse\n",
    "import pickle\n",
    "import random\n",
    "#from  model import HATT\n",
    "from torch_scatter import scatter\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.utils import softmax\n",
    "import sklearn.metrics\n",
    "import os\n",
    "\n",
    "from scipy.sparse import lil_matrix\n",
    "import argparse\n",
    "from graph.graph import LaplaceGraph\n",
    "from codes.dataset import FeaturesData, BPRTrainLoader, UserItemData\n",
    "from codes.performance import evaluate\n",
    "from session.run import Session\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5edaa122-86bc-4889-b64f-a92d1b0d17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp \n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9e4cc05-89f5-414c-ae6d-afde6bd82176",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be495582-7456-4e51-bc9d-b3783a964dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_ones(indices, size, dtype=torch.float):\n",
    "    one = torch.ones(indices.shape[1], dtype=dtype)\n",
    "    return torch.sparse.FloatTensor(indices, one, size=size).to(dtype)\n",
    "\n",
    "def to_tensor(graph):\n",
    "    graph = graph.tocoo()\n",
    "    values = graph.data\n",
    "    indices = np.vstack((graph.row, graph.col))\n",
    "    graph = torch.sparse.FloatTensor(torch.LongTensor(indices), torch.FloatTensor(values), \n",
    "                                          torch.Size(graph.shape))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e1eccb6-b48d-4086-9a35-cce76ad71425",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/c_u_train.txt','r') as file:\n",
    "    length = 0\n",
    "    culist = []\n",
    "    while 1:\n",
    "        line = file.readline()\n",
    "        if(line==''):\n",
    "            break\n",
    "        n = len(line)\n",
    "        s = line[0:n-1].split(',')\n",
    "        #print(s)\n",
    "        length += (len(s)-1)\n",
    "        for j in range(len(s)-1):\n",
    "            #print(s[0],s[j+1])\n",
    "            culist.append([int(s[0]),int(s[j+1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53069f68-e435-4989-bfe1-f1015c63aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/c_u_test.txt','r') as file:\n",
    "    length = 0\n",
    "    culist_test = []\n",
    "    while 1:\n",
    "        line = file.readline()\n",
    "        if(line==''):\n",
    "            break\n",
    "        n = len(line)\n",
    "        s = line[0:n-1].split(',')\n",
    "        #print(s)\n",
    "        length += (len(s)-1)\n",
    "        for j in range(len(s)-1):\n",
    "            #print(s[0],s[j+1])\n",
    "            culist_test.append([int(s[0]),int(s[j+1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12b348ad-8bfa-496e-94fb-813cc279e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/u_a.txt','r') as file:\n",
    "    length = 0\n",
    "    ualist = []\n",
    "    while 1:\n",
    "        line = file.readline()\n",
    "        if(line==''):\n",
    "            break\n",
    "        n = len(line)\n",
    "        s = line[0:n-1].split(',')\n",
    "        #print(s)\n",
    "        length += (len(s)-1)\n",
    "        for j in range(len(s)-1):\n",
    "            #print(s[0],s[j+1])\n",
    "            ualist.append([int(s[0]),int(s[j+1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efcc7ee3-ad02-4c36-8787-28bf265d83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/com_user_train.txt', 'w') as file:\n",
    "    for i in range(len(culist)):\n",
    "        file.write(str(culist[i][0]))\n",
    "        file.write(',')\n",
    "        file.write(str(culist[i][1]))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "426024b8-56e1-4336-b849-57f96409015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/com_user_test.txt', 'w') as file:\n",
    "    for i in range(len(culist_test)):\n",
    "        file.write(str(culist_test[i][0]))\n",
    "        file.write(',')\n",
    "        file.write(str(culist_test[i][1]))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "383db9b5-b55c-4466-829e-bae2e76b3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/user_attr.txt', 'w') as file:\n",
    "    for i in range(len(ualist)):\n",
    "        file.write(str(ualist[i][0]))\n",
    "        file.write(',')\n",
    "        file.write(str(ualist[i][1]))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc233827-198d-4fd7-9307-14d90e2cbf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users_test =  671\n",
    "n_users_train = 7771\n",
    "c = n_users_train+n_users_test\n",
    "n_coms = 453\n",
    "n_attrs = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6dc23e9b-d537-41fd-a6a2-8c518c039d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1101_1108/com_user_train.txt', 'r') as f:\n",
    "    C_U_train_pairs = list(map(lambda s: tuple(int(i) for i in s[:-1].split(',')), f.readlines()))\n",
    "indice = np.array(C_U_train_pairs, dtype=np.int32)\n",
    "values = np.ones(len(C_U_train_pairs), dtype=np.float32)\n",
    "ground_truth_c_u_train = sp.coo_matrix(\n",
    "    (values, (indice[:, 0], indice[:, 1])), shape=(n_coms, n_users)).tocsr()\n",
    "\n",
    "with open('1101_1108/com_user_test.txt', 'r') as f:\n",
    "    C_U_test_pairs = list(map(lambda s: tuple(int(i) for i in s[:-1].split(',')), f.readlines()))\n",
    "indice = np.array(C_U_test_pairs, dtype=np.int32)\n",
    "values = np.ones(len(C_U_test_pairs), dtype=np.float32)\n",
    "ground_truth_c_u_test = sp.coo_matrix(\n",
    "    (values, (indice[:, 0], indice[:, 1])), shape=(n_coms, n_users)).tocsr()\n",
    "\n",
    "with open('1101_1108/user_attr.txt', 'r') as f:\n",
    "    U_A_pairs = list(map(lambda s: tuple(int(i) for i in s[:-1].split(',')), f.readlines()))\n",
    "indice = np.array(U_A_pairs, dtype=np.int32)\n",
    "values = np.ones(len(U_A_pairs), dtype=np.float32)\n",
    "ground_truth_u_a = sp.coo_matrix(\n",
    "    (values, (indice[:, 0], indice[:, 1])), shape=(n_users, n_attrs)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "930be134-03cf-48b5-8956-f14427a75810",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_graph = [ground_truth_c_u_train, ground_truth_u_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "335e244c-6253-4229-aa35-f4bb5c73f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_transform(graph):\n",
    "    rowsum_sqrt = sp.diags(1/(np.sqrt(graph.sum(axis=1).A.ravel()) + 1e-8))\n",
    "    colsum_sqrt = sp.diags(1/(np.sqrt(graph.sum(axis=0).A.ravel()) + 1e-8))\n",
    "    graph = rowsum_sqrt @ graph @ colsum_sqrt\n",
    "    return graph\n",
    "\n",
    "def to_tensor(graph):\n",
    "    graph = graph.tocoo()\n",
    "    values = graph.data\n",
    "    indices = np.vstack((graph.row, graph.col))\n",
    "    graph = torch.sparse.FloatTensor(torch.LongTensor(indices), torch.FloatTensor(values), \n",
    "                                          torch.Size(graph.shape))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca3515bc-bbf2-4f2e-ad59-3cdfd029ef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 8442)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_c_u_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffc15a97-8a7b-43fa-93bd-b28073396da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8442, 94)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_u_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35be2a70-898e-4c5b-8f5a-5600031d09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_a_graph = lil_matrix((n_coms, n_attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e64f8ba-1b65-4867-b562-dd59ffe49032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<453x94 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_a_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f688b5e-3a60-48c5-a27e-1374b7dede1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UC_graph = sp.bmat([[sp.identity(raw_graph[0].shape[1])-sp.identity(raw_graph[0].shape[1]), raw_graph[0].T],\n",
    "                    [raw_graph[0], sp.identity(raw_graph[0].shape[0])-sp.identity(raw_graph[0].shape[0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60b744a5-253a-4047-ad67-b5ab1adc442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UA_graph = sp.bmat([[sp.identity(raw_graph[1].shape[0])-sp.identity(raw_graph[1].shape[0]), raw_graph[1]],\n",
    "                    [raw_graph[1].T, sp.identity(raw_graph[1].shape[1])-sp.identity(raw_graph[1].shape[1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da389c3a-841d-4d72-ba6c-3fa19975fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-C-A\n",
    "whole_graph = sp.bmat([[sp.identity(raw_graph[1].shape[0])-sp.identity(raw_graph[1].shape[0]), raw_graph[0].T, raw_graph[1]],\n",
    "                     [raw_graph[0], sp.identity(raw_graph[0].shape[0])-sp.identity(raw_graph[0].shape[0]),c_a_graph],\n",
    "                     [raw_graph[1].T, c_a_graph.T, sp.identity(raw_graph[1].shape[1])-sp.identity(raw_graph[1].shape[1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bc34260-5c8e-4c96-89b2-c5940df3de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8989x8989 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 473950 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11495a8c-ea7e-40e1-8d3e-add6689580b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_coms, n_attrs, raw_graph, args, device):\n",
    "        \n",
    "        super(LightGCN, self).__init__()\n",
    "        \n",
    "        self.n_users = n_users\n",
    "        self.n_coms = n_coms\n",
    "        self.n_attrs = n_attrs\n",
    "        self.emb_size = args.emb_size\n",
    "        self.batch_size = args.batch_size\n",
    "        self.decay = args.decay\n",
    "        self.layers = args.layers\n",
    "        self.device = device\n",
    "        self.cu_graph, self.ua_graph = raw_graph\n",
    "        self.mess_dropout = nn.Dropout(args.drop_rate, True)\n",
    "        self.node_dropout = nn.Dropout(args.drop_rate, True)\n",
    "        \n",
    "\n",
    "        user_emb_weight = self._weight_init(user_feat, n_users, args.emb_size)\n",
    "        com_emb_weight = self._weight_init(com_feat, n_coms, args.emb_size)\n",
    "        attr_emb_weight = self._weight_init(attr_feat, n_attrs, args.emb_size)\n",
    "\n",
    "        self.user_embeddings = nn.Embedding(self.n_users, self.emb_size, _weight=user_emb_weight)\n",
    "        self.com_embeddings = nn.Embedding(self.n_coms, self.emb_size, _weight=com_emb_weight)\n",
    "        self.attr_embeddings = nn.Embedding(self.n_attrs, self.emb_size, _weight=attr_emb_weight)\n",
    "        \n",
    "        \n",
    "        c_a_graph = lil_matrix((n_coms, n_attrs))\n",
    "        UC_graph = sp.bmat([[sp.identity(raw_graph[0].shape[1])-sp.identity(raw_graph[0].shape[1]), raw_graph[0].T],\n",
    "                    [raw_graph[0], sp.identity(raw_graph[0].shape[0])-sp.identity(raw_graph[0].shape[0])]])\n",
    "        self.uc_graph_tensor = to_tensor(laplace_transform(UC_graph)).to(device)\n",
    "        \n",
    "        UA_graph = sp.bmat([[sp.identity(raw_graph[1].shape[0])-sp.identity(raw_graph[1].shape[0]), raw_graph[1]],\n",
    "                    [raw_graph[1].T, sp.identity(raw_graph[1].shape[1])-sp.identity(raw_graph[1].shape[1])]])\n",
    "        self.ua_graph_tensor = to_tensor(laplace_transform(UA_graph)).to(device)\n",
    "        \n",
    "        whole_graph = sp.bmat([[sp.identity(raw_graph[1].shape[0])-sp.identity(raw_graph[1].shape[0]), raw_graph[0].T, raw_graph[1]],\n",
    "                     [raw_graph[0], sp.identity(raw_graph[0].shape[0])-sp.identity(raw_graph[0].shape[0]),c_a_graph],\n",
    "                     [raw_graph[1].T, c_a_graph.T, sp.identity(raw_graph[1].shape[1])-sp.identity(raw_graph[1].shape[1])]])\n",
    "        self.whole_graph_tensor = to_tensor(laplace_transform(whole_graph)).to(device)\n",
    "\n",
    "    def _weight_init(self, feat, rows, cols):\n",
    "\n",
    "        if feat is None:\n",
    "            free_emb = nn.init.normal_(torch.empty(rows, cols), std=0.01)\n",
    "            return free_emb\n",
    "        else:\n",
    "            free_emb = nn.init.normal_(torch.empty(rows, cols - feat.shape[-1]), std=0.01)\n",
    "            feat_emb = torch.tensor(feat) * 0.01\n",
    "            return torch.cat([free_emb, feat_emb], dim=1)\n",
    "        \n",
    "    def forward(self, graph):\n",
    "        # node dropout on graph\n",
    "        indices = graph._indices()\n",
    "        values = graph._values()\n",
    "        values = self.node_dropout(values)\n",
    "        graph = torch.sparse.FloatTensor(\n",
    "            indices, values, size=graph.shape)\n",
    "        # propagate\n",
    "        features = torch.cat([self.user_embeddings.weight, self.com_embeddings.weight, self.attr_embeddings.weight], dim=0)\n",
    "        all_features = [features]\n",
    "        for i in range(self.num_layers):\n",
    "            features = self.mess_dropout(torch.matmul(graph, features))\n",
    "            all_features.append(F.normalize(features))\n",
    "            \n",
    "        temp_features = all_features\n",
    "\n",
    "        all_features = torch.stack(all_features, dim = 1)\n",
    "        all_features = torch.mean(all_features, dim = 1)\n",
    "        A_feature, B_feature, C_feature= torch.split(\n",
    "            all_features, (n_users, n_coms, n_attrs), 0)\n",
    "        return A_feature, B_feature, C_feature, temp_features\n",
    "    \n",
    "    def evaluate(self, propagate_result, groups):\n",
    "        users_feature, items_feature, groups_feature,_ = propagate_result\n",
    "        groups_feature_atom, groups_feature_non_atom = [i[groups] for i in groups_feature] \n",
    "        items_feature_atom, items_feature_non_atom = items_feature \n",
    "        scores = torch.mm(groups_feature_atom, items_feature_atom.t()) \n",
    "        return scores\n",
    "\n",
    "    def predict(self, items_feature, groups_feature):\n",
    "        items_feature_atom, items_feature_non_atom = items_feature \n",
    "        groups_feature_atom, groups_feature_non_atom = groups_feature\n",
    "        pred = torch.sum(items_feature_atom * groups_feature_atom, 2)#+ torch.sum(items_feature_non_atom * groups_feature_non_atom, 2)\n",
    "        return pred\n",
    "\n",
    "    def get_embedding(self, user_emb, item_emb, users, pos_items, neg_items):\n",
    "        u_emb = user_emb[users]\n",
    "        pos_emb = item_emb[pos_items]\n",
    "        neg_emb = item_emb[neg_items]\n",
    "\n",
    "        return u_emb, pos_emb, neg_emb\n",
    "    \n",
    "\n",
    "    def bpr_loss(self, user_emb, pos_emb, neg_emb):\n",
    "        \n",
    "        pos_score = torch.sum(user_emb * pos_emb, dim=1)\n",
    "        neg_score = torch.sum(user_emb * neg_emb, dim=1)\n",
    "        mf_loss = torch.mean(F.softplus(neg_score - pos_score))\n",
    "        \n",
    "        reg_loss = (1/2) * (user_emb.norm(2).pow(2) + \n",
    "                            pos_emb.norm(2).pow(2) + \n",
    "                            neg_emb.norm(2).pow(2)) / user_emb.shape[0] * self.decay\n",
    "\n",
    "        loss = mf_loss + reg_loss\n",
    "        return loss, mf_loss, reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1066c9-ce12-4fba-880c-f62816c98cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebook/HATT/lightgcn'\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf08481-eba8-4ed0-a32a-f36b7bde43c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spent time: 7.0741026401519775s)\n",
      "epoch:1, loss:[0.528911] = mf:[0.527980] + reg:[0.000930]\n",
      "(spent time: 7.881688356399536s)\n",
      "recall@10:[0.051943], ndcg@10:[0.051303], recall@20:[0.075073], ndcg@20:[0.061611]\n",
      "(spent time: 7.189534425735474s)\n",
      "epoch:2, loss:[0.278241] = mf:[0.274569] + reg:[0.003672]\n",
      "(spent time: 5.373518943786621s)\n",
      "recall@10:[0.059028], ndcg@10:[0.058166], recall@20:[0.084658], ndcg@20:[0.069453]\n",
      "(spent time: 7.08504843711853s)\n",
      "epoch:3, loss:[0.214460] = mf:[0.209247] + reg:[0.005214]\n",
      "(spent time: 5.470014333724976s)\n",
      "recall@10:[0.063046], ndcg@10:[0.062957], recall@20:[0.091425], ndcg@20:[0.075436]\n",
      "(spent time: 7.141435384750366s)\n",
      "epoch:4, loss:[0.184809] = mf:[0.178683] + reg:[0.006126]\n",
      "(spent time: 7.935750484466553s)\n",
      "recall@10:[0.067485], ndcg@10:[0.067641], recall@20:[0.095714], ndcg@20:[0.080099]\n",
      "(spent time: 7.083908319473267s)\n",
      "epoch:5, loss:[0.163774] = mf:[0.157001] + reg:[0.006772]\n",
      "(spent time: 5.442552804946899s)\n",
      "recall@10:[0.069755], ndcg@10:[0.070747], recall@20:[0.099617], ndcg@20:[0.083886]\n",
      "(spent time: 7.100474834442139s)\n",
      "epoch:6, loss:[0.151065] = mf:[0.143798] + reg:[0.007267]\n",
      "(spent time: 7.032041072845459s)\n",
      "recall@10:[0.071868], ndcg@10:[0.072908], recall@20:[0.101842], ndcg@20:[0.086084]\n",
      "(spent time: 7.124865293502808s)\n",
      "epoch:7, loss:[0.140266] = mf:[0.132597] + reg:[0.007669]\n",
      "(spent time: 5.783630609512329s)\n",
      "recall@10:[0.073392], ndcg@10:[0.074474], recall@20:[0.103455], ndcg@20:[0.087695]\n",
      "(spent time: 6.941781520843506s)\n",
      "epoch:8, loss:[0.133114] = mf:[0.125114] + reg:[0.008000]\n",
      "(spent time: 7.092846870422363s)\n",
      "recall@10:[0.074457], ndcg@10:[0.075721], recall@20:[0.105098], ndcg@20:[0.089202]\n",
      "(spent time: 6.975513696670532s)\n",
      "epoch:9, loss:[0.126162] = mf:[0.117884] + reg:[0.008277]\n",
      "(spent time: 6.022852420806885s)\n",
      "recall@10:[0.076136], ndcg@10:[0.077270], recall@20:[0.106856], ndcg@20:[0.090802]\n",
      "(spent time: 7.1363725662231445s)\n",
      "epoch:10, loss:[0.121205] = mf:[0.112682] + reg:[0.008523]\n",
      "(spent time: 7.3138206005096436s)\n",
      "recall@10:[0.077029], ndcg@10:[0.078633], recall@20:[0.108573], ndcg@20:[0.092534]\n",
      "(spent time: 6.97111701965332s)\n",
      "epoch:11, loss:[0.117198] = mf:[0.108459] + reg:[0.008739]\n",
      "(spent time: 5.757030725479126s)\n",
      "recall@10:[0.077557], ndcg@10:[0.079569], recall@20:[0.110221], ndcg@20:[0.093954]\n",
      "(spent time: 6.96743631362915s)\n",
      "epoch:12, loss:[0.112739] = mf:[0.103819] + reg:[0.008920]\n",
      "(spent time: 5.756938695907593s)\n",
      "recall@10:[0.078635], ndcg@10:[0.080641], recall@20:[0.111692], ndcg@20:[0.095176]\n",
      "(spent time: 6.948326826095581s)\n",
      "epoch:13, loss:[0.108150] = mf:[0.099047] + reg:[0.009103]\n",
      "(spent time: 7.466710567474365s)\n",
      "recall@10:[0.079261], ndcg@10:[0.081384], recall@20:[0.112702], ndcg@20:[0.096091]\n",
      "(spent time: 6.920049667358398s)\n",
      "epoch:14, loss:[0.106786] = mf:[0.097523] + reg:[0.009263]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-119:\n",
      "Process ForkPoolWorker-118:\n",
      "Process ForkPoolWorker-120:\n",
      "Process ForkPoolWorker-117:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 58, in test_one_perf\n",
      "    score_indices = largest_indices(score, topks)\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 59, in test_one_perf\n",
      "    result = get_perf(score_indices, uid_test_pos_items, topks)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 58, in test_one_perf\n",
      "    score_indices = largest_indices(score, topks)\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 75, in get_perf\n",
      "    topk_eval[i * 2 + 1] = ndcg_k(rank[:topk], uid_test_pos_items)\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 66, in largest_indices\n",
      "    indices = np.argpartition(score, -max_topk)[-max_topk:]\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 58, in test_one_perf\n",
      "    score_indices = largest_indices(score, topks)\n",
      "  File \"/notebook/HATT/lightgcn/utility/metrics.py\", line 25, in ndcg_k\n",
      "    if id not in ground_truth:\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 66, in largest_indices\n",
      "    indices = np.argpartition(score, -max_topk)[-max_topk:]\n",
      "  File \"/notebook/HATT/lightgcn/codes/performance.py\", line 66, in largest_indices\n",
      "    indices = np.argpartition(score, -max_topk)[-max_topk:]\n",
      "KeyboardInterrupt\n",
      "  File \"<__array_function__ internals>\", line 6, in argpartition\n",
      "  File \"<__array_function__ internals>\", line 6, in argpartition\n",
      "  File \"<__array_function__ internals>\", line 6, in argpartition\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 832, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 832, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 832, in argpartition\n",
      "    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3baf8ec2b2d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                  \u001b[0mtrain_U2I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                                  \u001b[0mtest_U2I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                                  args)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall@10:[{:.6f}], ndcg@10:[{:.6f}], recall@20:[{:.6f}], ndcg@20:[{:.6f}]\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mperf_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/HATT/lightgcn/utility/decorate.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mspent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/HATT/lightgcn/codes/performance.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(user_emb, item_emb, n_users, n_items, train_U2I, test_U2I, args)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mperf_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_speed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_U2I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_U2I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mperf_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/HATT/lightgcn/codes/performance.py\u001b[0m in \u001b[0;36mperformance_speed\u001b[0;34m(scores, train_U2I, test_U2I, args)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_user_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_U2I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_U2I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mall_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_one_perf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_perf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_perf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"gcn\")\n",
    "    parser.add_argument('--dataset_name', default='gowalla', type=str)\n",
    "    parser.add_argument('--data_path', default=root + '/data', type=str)\n",
    "    \n",
    "    parser.add_argument('--emb_size', default=64, type=int)\n",
    "    parser.add_argument('--num_epoch', default=1000, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--decay', default=0.001, type=float)\n",
    "    parser.add_argument('--layers', default=3, type=int)\n",
    "    parser.add_argument('--batch_size', default=4096, type=int)\n",
    "\n",
    "    parser.add_argument('--topks', default='[10,20]', type=str)\n",
    "    parser.add_argument('--log', default=root + '/log/lightgcn.txt', type=str)\n",
    "    parser.add_argument('--parameters_path', default= root + '/parameters/lightgcn', type=str)\n",
    "    parser.add_argument('--cores', default=4, type=int)\n",
    "    \n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "def get_dataloader(train_set, train_U2I, n_items, batch_size, cores):\n",
    "    gcn_dataloader = BPRTrainLoader(train_set, train_U2I, n_items)\n",
    "    gcn_dataloader = DataLoader(gcn_dataloader, batch_size, num_workers=cores, shuffle=True)\n",
    "\n",
    "    return gcn_dataloader\n",
    "\n",
    "def test(model, n_users, n_items):\n",
    "\n",
    "    user_emb, item_emb = model.propagate()\n",
    "    return user_emb.cpu().detach().numpy(), item_emb.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "\n",
    "    # load movielens-1m\n",
    "    # data = FeaturesData(args.data_path, args.dataset_name)\n",
    "    # train_set, train_U2I, test_U2I, n_users, n_items, user_feat = data.load()\n",
    "\n",
    "    # load gowall\n",
    "    data = UserItemData(args.data_path, args.dataset_name)\n",
    "    train_set, train_U2I, test_U2I, n_users, n_items = data.load()\n",
    "\n",
    "    loader = get_dataloader(train_set, train_U2I, n_items, args.batch_size, args.cores)\n",
    "    g = LaplaceGraph(n_users, n_items, train_U2I)\n",
    "    adj = g.generate().cuda()\n",
    "\n",
    "    gcn = LightGCN(n_users, n_items, adj, args)\n",
    "    gcn = gcn.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(gcn.parameters(), lr=args.lr)\n",
    "\n",
    "    sess = Session(gcn)\n",
    "\n",
    "    f = open(args.log, 'w+')\n",
    "    for epoch in range(args.num_epoch):\n",
    "\n",
    "        loss = sess.train(loader, optimizer, args)\n",
    "        print(\"epoch:{:d}, loss:[{:.6f}] = mf:[{:.6f}] + reg:[{:.6f}]\".format(epoch+1, *loss))\n",
    "        print(\"epoch:{:d}, loss:[{:.6f}] = mf:[{:.6f}] + reg:[{:.6f}]\".format(epoch+1, *loss), file=f)\n",
    "\n",
    "        gcn.eval()\n",
    "        with torch.no_grad():\n",
    "            user_emb, item_emb = test(gcn, n_users, n_items)\n",
    "            perf_info = evaluate(user_emb,\n",
    "                                 item_emb,\n",
    "                                 n_users,\n",
    "                                 n_items,\n",
    "                                 train_U2I,\n",
    "                                 test_U2I,\n",
    "                                 args)\n",
    "\n",
    "            print(\"recall@10:[{:.6f}], ndcg@10:[{:.6f}], recall@20:[{:.6f}], ndcg@20:[{:.6f}]\".format(*perf_info), file=f)\n",
    "            print(\"recall@10:[{:.6f}], ndcg@10:[{:.6f}], recall@20:[{:.6f}], ndcg@20:[{:.6f}]\".format(*perf_info))\n",
    "            \n",
    "            # save embedding\n",
    "            # torch.save((user_emb, item_emb), f=args.parameters_path + '_' + str(epoch + 1) + '.pth')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db012b05-5a96-4f35-ae0b-dc42d40efca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3bed3-9407-4373-a8f8-ae1310dbc408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
